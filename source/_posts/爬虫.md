---
title: 爬虫
date: 2017-12-05 11:23:09
tags: [数据分析]
---

爬虫学习记录<!--more-->

# Scrapy
## 安装
`conda install -c conda-forge scrapy`
## 创建工程
`scrapy startproject ArticleSpider`
## 配置 Pycharm使其可以断点 Scrapy
添加一个 main 函数,通过 scrapy.cmd.execute 来执行 scrapy 命令行
## XPath 语法
[XPath 语法](http://www.w3school.com.cn/xpath/xpath_syntax.asp)

*ps:如果你只想获得第一个匹配的，可以使用.extract_first()*
## 爬虫去重策略
![](https://ws1.sinaimg.cn/large/006tNc79gy1fqjaoknqm1j318e0qsgq9.jpg)

## tips
```python
from urllib import parse
parse.urljoin(base, url) # 在某些提取到到 href是一个相对路径是需要手动组装 url
```
![](https://ws1.sinaimg.cn/large/006tNc79gy1fqjaoltmulj31kw0bwn2l.jpg)
利用 scrapy 自带的 ImagesPipeline快速完成图片下载以及下载格式设置


python3 里所有的字符都是 unicode, 需要 encode 才能被某些函数接受

codecs 来完成文件的打开和写入,可以避免很多文件编码的问题
mysql varchar 必须制定长度,很长的内容可以用 longtext 类型,不用指定长度

可以利用scrapy的 adbapi 可以实现异步存 mysql.

Requeset 对象不添加 callback 参数默认进入到`parse(self.Response)` 函数中
在 setting文件中COOKIES_ENABLED = True打开,这样后续的请求会自动带上 cookie

![](https://ws1.sinaimg.cn/large/006tNc79gy1fqjaomho2bj31kw0tvwk1.jpg)

-  终端添加 user_agent
`scrapy shell -s USER_AGENT='custom user agent' 'http://www.example.com'`
- scrapy 默认采取的深度优先算法

## cookie 和 session 的关系与区别
cookie 是浏览器提供的一种机制
session 是后台的一种保存回话的机制. sessionId是 session 的 key(索引值),
通过返回给 client(浏览器),保存到 cookie 中来实现区别出clinet 的功能.而且安全
最原始是通过 cookie 直接保存账号密码的.[具体可以参考](https://coding.imooc.com/lesson/92.html#mid=2850)
## 多说一句
cookie 和 http 的 body 都可以用来传输数据.但是 cookie 里面的数据是每个请求都会带上的,而且是可以很容器
获取的,而 body 是每个请求特有的.这样,如果是所有请求都需要的数据就放到 cookie 里面去,而请求特有的数据那就
放到 body 里去.


## 坑
现代浏览器会给每一个 table 标签渲染出 tbody，不管网页原始的 html 代码中是否存在 tbody。因而在 Chrome 中调试好的 xpath 选择器表达式放到 Scrapy 项目中，很有可能就会匹配不到数据。在 Scrapy 中使用 tbody 作为 xpath 选择器标签时，在控制台调试表达式时，一定要查看网页源代码，确认源代码中是否有 tbody，Scrapy 是直接在源代码中匹配提取而不会想浏览器给所有的 table 元素渲染出 tbody。此外，xpath 选择器应当与 css 选择器一样遵守尽量少使用嵌套的表达式。


## 反爬
![](https://ws3.sinaimg.cn/large/006tNc79gy1fqjaon6jhpj31i80xk44x.jpg)
- 尽量禁用 cookie, 除非需要登录
- 开启限速功能,[参考官方文档](http://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/autothrottle.html)
- 可以为具体项目自定义 setting, 设置`custom_settings`
- Tor代理
- 代理池(不建议使用,速度太慢,不稳定)


## 调试
1. 不需要登录可以直接在终端通过`scrapy shell https://www.example.com`的方式来调试 xpath或者 css
2. 另外一种可以通过在代码中调用`inspect_response(response, self)`来实现现场断点,在一些需要登录的情况下用这个,[具体可以参考](https://doc.scrapy.org/en/latest/topics/shell.html#topics-shell-inspect-response)

## Tor+ Privoxy 实现免费国外代理
[具体可以这个教程](http://ibloodline.com/articles/2017/12/30/tor.html)
注意:需要将文中的`HTTPProxy 127.0.0.1:1087
HTTPSProxy 127.0.0.1:1087` 可以改成 Sock5Proxy 试试.另外改完配置记得在终端启动 tor
直接输入 tor 即可启动.这个虽然能够拿到稳定的代理,但都是国外的,这对于一些国内网站来说就比较尴尬
国外用户访问不了国内的网站就不行

## Scrapy 源码解析
![](https://ws1.sinaimg.cn/large/006tNc79gy1fqjaoo3jwaj312w0q4mzl.jpg)


## 开源代理池
https://github.com/SpiderClub/haipproxy
https://github.com/chenjiandongx/async-proxy-pool
https://github.com/imWildCat/scylla
## 待做
[深圳房价分析](https://mp.weixin.qq.com/s/DAbdoYZzdyZfReQbfd0lCg)
[github scrapy 最佳实践](https://github.com/kezhenxu94/house-renting)
# 文档
[scrapy](http://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/tutorial.html)

[selenium](http://selenium-python-zh.readthedocs.io/en/latest/getting-started.html)

[另一个类似 selenium 的东东,api 可能比 selenium 好用吧](https://github.com/cobrateam/splinter)

[Request](http://docs.python-requests.org/zh_CN/latest/index.html)

[fake useragent](https://github.com/hellysmile/fake-useragent)

[代理对比购买](https://cuiqingcai.com/5094.html)

[scrapy-proxy,用的本地文件,不太好管理](https://github.com/aivarsk/scrapy-proxies)

[scrapy-crawler,全自动,需收费](https://github.com/scrapy-plugins/scrapy-crawlera)
