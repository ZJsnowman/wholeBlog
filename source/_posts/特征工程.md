---
title: 特征工程
date: 2018-12-22 17:42:33
tags:
---

# 基本数据结构

![基本数据结构模型](https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/blog/2018-12-22-Paper.%E7%B4%A0%E6%8F%8F.1.png)
上图为特征工程需要了解的基本的数据结构模型。可以看做是一个DataFrame。


下面我们分别从横向和纵向分别来对数据做一些处理。
横向如果特征过多，我们就需要做一个特征选择。主要两个办法

- 特征选择 选择一些特征出来，还是原有特征，从100个选10个。
- 进行降维，生成新的变量，这些新的变量彼此不相关。从100个生成新的10个变量，这10个变量是原来没有的。比如使用主成分分析和因子分析

纵向来看，在多个样本的情况下，我们可以做聚类。比如K-mean。当然还有很多其他的聚类算法

## 主成分分析和因子分析

### 注意点

- 原始变量之间的相关程度高，降维效果就比较好，否则意义不大。所以可以先查看相关系数矩阵，看看适合做降维不

- 降维之前先做标准化最好，消除水平和量纲上的影响。

- PCA的一个主要缺点就是不好解释，所以人们发明了因子分析，可以使结果尽可能达到易于解释且合理。

## 聚类

### 注意

- 做完k-mean，需要做一个方差分析，来检验分的时候合理
- 分类如果含有分类变量，需要使用新的聚类方法，比如两步聚类法，密度聚类，谱聚类，混合高斯，这里可以查询资料
- 聚类如果变量太多，还需要先做特征选择，也就是将行缩短
- 双向聚类，就是在变量(行方向)，和样本(列方向)同时聚类，查阅资料。

问题
多重共线性 
降维后如何解释，这也是pca的缺点，不好解释。
主成分本质上就是特征向量，可以了解一下特征向量的求法，图像上就是椭圆的主轴。
相关系数矩阵里面有分类数据，如何处理，哑变量问题
如果有分类变量，需要做方差分析，需要去了解方差分析。

## 多重共线性

多重共线性指的是回归模型中，两个或两个以上的自变量彼此相关。带来的问题是可能会对
结果造成混乱，对参数的系数的正负号产生影响，从而误导整个分享方向。
举例：
x1=x2
y~a1\*x1+a2\*x2
实际等价于:y~(a1+a2)x1
假设(a1+a2)=2,也就是说x1变化一个单元，y正向增加2个单元。但是共线性可能会导致a1=-1,a2=3,这样也是符合的。这样就会误导以为y和x1负相关，x2正相关。

所以特征选择还是很有必要的，如果变量之间有很强的关系。如果变量比较少，观察相关系数矩阵就可以判断，如果比较多，就需要去其他方法去判断，比如计算容忍度之类的。可以简单的去掉双胞胎变量，也可以通过一些向向前选择，逐步回归等方法进行变量选择。当然这些选择和PCA是不同的，那还是保留原有变量的，而不是生成新的变量。



