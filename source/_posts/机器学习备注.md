---
title: 机器学习
date: 2099-11-27 17:20:02
tags: [数据分析]
---
![](/images/machineLearning.png)
机器学习备注<!--more-->
# Naive Bayes(贝叶斯推断)
[讲解贝叶斯基本算法原理](http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html)

## 朴素贝叶斯为啥朴素
因为贝叶斯算法并没有考虑事情发生的顺序.
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fm10v16uz3j31c00s6n29.jpg)

## 朴素贝叶斯的优势和劣势
- 优势

这种算法非常适合文本分类。在处理文本时，常见的做法是将每个单词看作一个特征，这样就会有大量的特征。此算法的相对简单性和朴素贝叶斯独立特征的这一假设，使其能够出色完成文本的分类
- 劣势

当事情的顺序很重要的时候,就不行.比如早起 google芝加哥公牛的时候.就会出现一些芝加哥的介绍或者公牛的照片.但是明显芝加哥公牛有其他的意思.这个时候贝叶斯就不是很管用的

- 总结

如何避免这些,我们采用的监督式学习.也就有试验和测试数据.通过测试就能够知道算法是否有效


# SVM(支持向量机)

核心概念- 间隔(margin)  
- 支持向量机的内部原理是最大程度提高结果稳健性
- 正确分类标签作为首要考虑,然后对间隔进行最大化.也就是说要在分类正确的前提下对间隔最大化
- SVM 可以忽略异常值,然后使间隔最大化

SVM 不适合处理海量数据,训练时间太慢了
噪声过多情况下,类严重重叠,边界不明显也不适合 SVM. 可以考虑用 Navie Bayes

[参考 udacity 学习笔记](http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-33-SVM/)


# Decision Trees (决策树)

## 信息熵
[信息熵的定义](http://www.ruanyifeng.com/blog/2014/09/information-entropy.html)
## 信息增益

## 优缺点
容易过拟合
[决策树理解,讲的不错](http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html)
[udacity 学习笔记](http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-34-DecisionTrees/)


# k-nearest neighbors
[查考](https://zhuanlan.zhihu.com/p/25994179)
[udacity学习笔记](http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-39-cluster/)

# 集成学习
[参考](http://www.cnblogs.com/pinard/p/6131423.html)


# adaboost


# random forest


# 准确度与训练集大小的关系
更大的数据量要比经过精密调整的算法提供更好的结果,更大的数据能够取得更好的效果,这是
机器学习领域至理名言

# 数据类型
- numberical 数值
- categorical  分类
- time series  时序
- text  文字

# 判断离散还是连续
**关注顺序**

有些不好判断的类型,可以关注数据之间的顺序,如果之间有强烈的关联性,则用连续性的分类器,否则就用离散性的分类器.比如,公司100个人, 工号从1-100,如果需要给他们分类,最好就用离散性的分类器,因为不同工号之前没有关联性


# 回归(regression)
## 最小二乘法
也叫[最小平方法](https://www.wikiwand.com/zh-hans/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95)

## 线性回归
y=m*x+b 寻找系数和截距,通过最小化误差平方和
### 线性回归误差
误差=真实值-误差值 (注意存在正负值)
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fncgcuvaysj31kw0wm7dq.jpg)
通过上图,可以看出为啥不用误差绝对值的和而是用平方和的原因.用误差绝对值的和会存在多条线,
而用平方和就只会有一条

### 误差平法和
判断拟合质量的标准
#### 最小化误差平方和的算法
- 普通最小二乘法 ordinary least squares(sklearn LinearRegression中使用就是这种)
- 梯度下降 gradient descent

#### 问题
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fncgkyzpwqj31kw0sq0xw.jpg)
当对不同数量的两个数据进行用最小误差平方和来评判算法好坏时会出现问题.拟合效果可能差不多,由于数量多的那个数据集天然误差平方和会大

## 决定系数 R suqre
[定义](https://www.wikiwand.com/zh-hans/%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0)

决定系数的出现是为了解决上面误差平方和的缺陷.介于0-1之间,1最好,0最差.

## 监督分类和回归的区别
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fnchoi581lj31kw0vwdu1.jpg)

## 多元回归(多变量回归)


# 异常值
## 原因
- 传感器故障
- 数据输入错误

## 去除异常值的算法

1. 回归
2. 根据误差值排序,去除前10%
3. 重新回归


# Clustering(聚类)
## K-means
1. 将各个点分配到矩心
2. 移动矩心,使各个点到矩心的距离最短
反复执行上面两个步骤
## K-means的局限
依赖最初矩心所在的位置,不同的位置最终的结果可能会不同.
局部最小解



# 特征缩放
特征缩放的公式(x'-x_min)/(x_max-x_min)
## 受此影响的机器学习算法
- 使用 RBF 核函数的 SVM
- K-means

# 涉及的一些中英对照
```
slope->斜率
intercept->截距
coefficient->系数
```

# 文本
bag of words -词袋
stop words - 停止词
stemmer- 词干提取
TF-IDF
TF-Term Frequency
IDF-Inverse Document Frequency

[TF-IDF解释](http://www.ruanyifeng.com/blog/2013/03/tf-idf.html)




# 特征选择
## 正则化
为了防止过拟合采用的一种手段,在最小化sse(误差平方和) 的同时增加惩罚措施.
避免采用过多的特征维度.采用维度过少会导致高偏差(high bias,误差平方和较大).采用维度过度
会导致高方差(high varaiance,对测试数据集拟合不佳,不具有普遍性)
- 正则化回归例如: LASSO 回归
[Udacity 学习笔记1](http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-42-CreateFeature/#16-%E5%A5%97%E7%B4%A2%E5%9B%9E%E5%BD%92)
# 一些其他的点
- 过拟合就是在训练集上准确率非常高，而在测试集上准确率低

# PCA
- 一种用来降维的手段.是一种将输入特征转换为其主要特征的系统化方法
- 主成分的定义是数据中使方差最大话的方向(数据在上投影,使数据丢失的可能性降到最低)
- 主成分的上限是输入特征数量,当等于输入特征数量时就没有意义了,通常只会使用前面几个主成分
- PCA最好在特征选择之前做.

# 交叉验证
[udacity 学习笔记参考](http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-44-cross-validation/)


# 方差偏差均衡
[参考](https://plushunter.github.io/2017/04/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8818%EF%BC%89%EF%BC%9A%E6%96%B9%E5%B7%AE%E5%81%8F%E5%B7%AE%E6%9D%83%E8%A1%A1%EF%BC%88Bias-Variance%20Tradeoff%EF%BC%89/)


# 总结
![](https://ws3.sinaimg.cn/large/006tKfTcgy1fptfk7czl6j31kw0vnjx6.jpg)


总的流程
1. 基本数据情况
2. 检查数据无效值(NaN,NULL等)
3. 绘图查看异常点
4. 删除异常值
5. 添加新特征
6. 特征选择
7. 特征缩放
8. 应用算法+网格搜索


## 模型选择
[sklearn 官方模型选择指导](http://scikit-learn.org/stable/tutorial/machine_learning_map/)

[Microsoft Azure 官网模型推荐](https://docs.microsoft.com/zh-cn/azure/machine-learning/studio/algorithm-cheat-sheet)


## 泰坦尼克存活预测
[Kaggle地址](https://www.kaggle.com/c/titanic)]

[参考地址,重点学习一下流程以及模型融合](https://zhuanlan.zhihu.com/p/31743196)
[参考地址2,寒小阳逻辑回归建模](https://blog.csdn.net/han_xiaoyang/article/details/49797143)


## 模型融合
[Kaggle机器学习之模型融合（stacking）心得](https://zhuanlan.zhihu.com/p/26890738)

[模型融合方法概述](https://zhuanlan.zhihu.com/p/25836678)

[Bagging与随机森林,对西瓜书的一个总结](https://jlunevermore.github.io/2016/06/25/14.Bagging%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/?utm_source=tuicool&utm_medium=referral)

## udacity 总结挺好必看
[偶像](http://road2autodrive.info/)
## HDFS
https://mp.weixin.qq.com/s/3QFQRL708Muxf_QzKmSMlw

## 牛人总结
[分享一波关于做Kaggle比赛，Jdata，天池的经验，看完我这篇就够了](https://segmentfault.com/a/1190000012084849)

[如何建立自己的应用型机器学习流程](https://mp.weixin.qq.com/s?__biz=MzI0NzE3NTAzOA%3D%3D&mid=2652115209&idx=2&sn=003a5e0a8fdc4e4d9755b18031763796#wechat_redirect)

## Kaggle 入门
[初学者应该参加哪些 Kaggle 比赛](https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA%3D%3D&mid=2650668868&idx=3&sn=ba389178ad651a78e35b3f16bb6ae560#wechat_redirect)

[Kaggle 六大比赛最全面解析](https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&mid=2650670710&idx=1&sn=d75a077506c72eb5ba5d59c063cc0dda&chksm=bec23b0589b5b213e1900c7f963d2e380e4df24726e070ac5f88d9b9e8b1f37bf06b32fe762b&mpshare=1&scene=1&srcid=0409PduieO4ncwIVbg5YsaqW#rd)

## 好的视频资料
[2017年度好视频](https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&mid=2650668953&idx=1&sn=68b70229dd96466ef0252ba672002f39&chksm=bec1c2ea89b64bfce5e5a286041d5da8df44fc519b72e999ece90dc8d8b4e75d4862eb8a5a84&mpshare=1&scene=1&srcid=1231OlnWXrdIR0QUx6a5bX2j#rd)

## 深度学习机器学习常见工具包 cheatsheet
https://github.com/kailashahirwar/cheatsheets-ai

## 机器学习所需要的数学知识
[一文读懂机器学习需要哪些数学知识](https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&mid=2650670694&idx=1&sn=687dbfba5890cca3c082a1c373f04ba8&chksm=bec23b1589b5b203a7b78d689b6469392a11133e9ae3558d71130cb75cf57dba1287c3de529d&mpshare=1&scene=1&srcid=0409NwpiY3TIBsTdYowz87zC#rd)


[机器学习数学知识](https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&mid=2650670670&idx=1&sn=8b3c114e542843a81599dcf6c8441e8d&chksm=bec23b3d89b5b22bc37d6202a0276cd7824b38a617c1f1deab0d70d63b35ec48db735124b2b4&mpshare=1&scene=1&srcid=0409cR4X0hRgCTEqKh383YaN#rd)
